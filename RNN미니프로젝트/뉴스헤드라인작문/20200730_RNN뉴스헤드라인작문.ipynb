{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596070488531",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>뉴욕타임스 기사 학습 후 텍스트생성</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np \n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1324 entries, 0 to 1323\nData columns (total 15 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   articleID         1324 non-null   object\n 1   articleWordCount  1324 non-null   int64 \n 2   byline            1324 non-null   object\n 3   documentType      1324 non-null   object\n 4   headline          1324 non-null   object\n 5   keywords          1324 non-null   object\n 6   multimedia        1324 non-null   int64 \n 7   newDesk           1324 non-null   object\n 8   printPage         1324 non-null   int64 \n 9   pubDate           1324 non-null   object\n 10  sectionName       1324 non-null   object\n 11  snippet           1324 non-null   object\n 12  source            1324 non-null   object\n 13  typeOfMaterial    1324 non-null   object\n 14  webURL            1324 non-null   object\ndtypes: int64(3), object(12)\nmemory usage: 155.3+ KB\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       Former N.F.L. Cheerleaders’ Settlement Offer: ...\n1       E.P.A. to Unveil a New Rule. Its Effect: Less ...\n2                                 The New Noma, Explained\n3                                                 Unknown\n4                                                 Unknown\n                              ...                        \n1319    This Common Question Reinforces the Gender Pay...\n1320                                   Anna, Llama and Me\n1321           Gen. Michael Hayden Has One Regret: Russia\n1322                         There Is Nothin’ Like a Tune\n1323                                              Unknown\nName: headline, Length: 1324, dtype: object"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "df=pd.read_csv(\"nyt.csv\")\n",
    "# df.head()['webURL']\n",
    "df.info()\n",
    "df.head(1)['snippet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df['headline'].isnull().sum()\n",
    "df['headline'].isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.headline.values\n",
    "list(df.headline.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n 'The New Noma, Explained',\n 'Unknown',\n 'Unknown',\n 'Unknown',\n 'Unknown',\n 'Unknown',\n 'How a Bag of Texas Dirt  Became a Times Tradition',\n 'Is School a Place for Self-Expression?']"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "headline = []\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1324"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "len(headline) #1324개 = unknown포함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1214"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "headline=[n for n in headline if  n != 'Unknown'] # n이 Unknown하고 같이 않을 때 제목으로 뽑겠다 \n",
    "len(headline) #1214개 = unknown 불포함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n 'The New Noma, Explained',\n 'How a Bag of Texas Dirt  Became a Times Tradition',\n 'Is School a Place for Self-Expression?']"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "print(punctuation) # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "f\n==================================================\no\n==================================================\nr\n==================================================\nm\n==================================================\ne\n==================================================\nr\n==================================================\n \n==================================================\nn\n==================================================\nf\n==================================================\nl\n==================================================\n \n==================================================\nc\n==================================================\nh\n==================================================\ne\n==================================================\ne\n==================================================\nr\n==================================================\nl\n==================================================\ne\n==================================================\na\n==================================================\nd\n==================================================\ne\n==================================================\nr\n==================================================\ns\n==================================================\n’\n==================================================\n \n==================================================\ns\n==================================================\ne\n==================================================\nt\n==================================================\nt\n==================================================\nl\n==================================================\ne\n==================================================\nm\n==================================================\ne\n==================================================\nn\n==================================================\nt\n==================================================\n \n==================================================\no\n==================================================\nf\n==================================================\nf\n==================================================\ne\n==================================================\nr\n==================================================\n \n==================================================\n1\n==================================================\n \n==================================================\na\n==================================================\nn\n==================================================\nd\n==================================================\n \n==================================================\na\n==================================================\n \n==================================================\nm\n==================================================\ne\n==================================================\ne\n==================================================\nt\n==================================================\ni\n==================================================\nn\n==================================================\ng\n==================================================\n \n==================================================\nw\n==================================================\ni\n==================================================\nt\n==================================================\nh\n==================================================\n \n==================================================\ng\n==================================================\no\n==================================================\no\n==================================================\nd\n==================================================\ne\n==================================================\nl\n==================================================\n"
    }
   ],
   "source": [
    "s = 'former nfl cheerleaders’ settlement offer 1 and a meeting with goodel'\n",
    "for c in s:\n",
    "    print(c)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "''"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# \"’\" <-처리가 안되었음 유니코드이기 때문에 코드를 변환해줘야함.\n",
    "\"’\".encode('utf8').decode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n 'epa to unveil a new rule its effect less science in policymaking',\n 'the new noma explained',\n 'how a bag of texas dirt  became a times tradition',\n 'is school a place for selfexpression']"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "##함수 생성\n",
    "def repreprocessing(s):\n",
    "    s=s.encode('utf8').decode('ascii', 'ignore') # ’를 지우기 위해\n",
    "    return ''.join(c for c in s if c not in punctuation).lower() # c는 뉴스기사 \n",
    "    # print(s) # headlines' names\n",
    "    # print(\"=\"*50)\n",
    "    #s에 전달된 뉴스기사 제목에 대해 전처리(점 제거, 소문자)\n",
    "    #그런데 ' <-가 제거가 안되었음. 따로 제거 해야함.\n",
    "    \n",
    "text=[repreprocessing(x) for x in headline ]\n",
    "#               <-2->           <- 1 ->\n",
    "text[:5]\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3493\n1214\n"
    }
   ],
   "source": [
    "t.word_index\n",
    "print(len(t.word_index)) # 3493개 단어 \n",
    "print(len(text)) #1214개 뉴스기사 헤드라인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize=len(t.word_index)+1 # 3493개 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[99, 269],\n [99, 269, 371],\n [99, 269, 371, 1115],\n [99, 269, 371, 1115, 582],\n [99, 269, 371, 1115, 582, 52],\n [99, 269, 371, 1115, 582, 52, 7],\n [99, 269, 371, 1115, 582, 52, 7, 2],\n [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n [100, 3]]"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "sequences = []\n",
    "for line in text: # 1214개 헤드라인 , 3493개 단어 \n",
    "    encoded=t.texts_to_sequences([line])[0] # \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence=encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "sequences[:11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t.word_counts # 단어들의 등장 횟수 \n",
    "t.word_index # 단어들의 인덱스\n",
    "\n",
    "indextoWord = {} # indextoWord에 v인덱스에 해당하는 k단어를 저장할것이다.\n",
    "for k, v in t.word_index.items():\n",
    "    indextoWord[v] = k # {1:'the}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dept\n"
    }
   ],
   "source": [
    "print(indextoWord[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "24\n"
    }
   ],
   "source": [
    "maxLen=max(len(s) for s in sequences)\n",
    "print(maxLen) # 가장긴 것 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0   99  269]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0   99  269  371]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0   99  269  371 1115]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0   99  269  371 1115  582]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0   99  269  371 1115  582   52]]\n"
    }
   ],
   "source": [
    "sequences=pad_sequences(sequences, maxlen=maxLen, padding='pre')\n",
    "print(sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 99]\n269\n"
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "#ex) 1=010000000000, 11=000000000001\n",
    "y = to_categorical(y, num_classes=vocabSize)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(7803, 3494)"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "y.shape # (7803, 3494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델생성\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, SimpleRNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/200\n244/244 [==============================] - 3s 12ms/step - loss: 7.6565 - accuracy: 0.0288\nEpoch 2/200\n244/244 [==============================] - 3s 13ms/step - loss: 7.1263 - accuracy: 0.0309\nEpoch 3/200\n244/244 [==============================] - 3s 13ms/step - loss: 6.9902 - accuracy: 0.0322\nEpoch 4/200\n244/244 [==============================] - 3s 13ms/step - loss: 6.8649 - accuracy: 0.0413\nEpoch 5/200\n244/244 [==============================] - 3s 13ms/step - loss: 6.7223 - accuracy: 0.0436\nEpoch 6/200\n244/244 [==============================] - 3s 12ms/step - loss: 6.5675 - accuracy: 0.0470\nEpoch 7/200\n244/244 [==============================] - 3s 13ms/step - loss: 6.4238 - accuracy: 0.0483\nEpoch 8/200\n244/244 [==============================] - 3s 12ms/step - loss: 6.2705 - accuracy: 0.0528\nEpoch 9/200\n244/244 [==============================] - 3s 13ms/step - loss: 6.0386 - accuracy: 0.0583\nEpoch 10/200\n244/244 [==============================] - 3s 13ms/step - loss: 5.8621 - accuracy: 0.0634\nEpoch 11/200\n244/244 [==============================] - 3s 12ms/step - loss: 5.6951 - accuracy: 0.0646\nEpoch 12/200\n244/244 [==============================] - 3s 14ms/step - loss: 5.5303 - accuracy: 0.0707\nEpoch 13/200\n244/244 [==============================] - 3s 14ms/step - loss: 5.3706 - accuracy: 0.0764\nEpoch 14/200\n244/244 [==============================] - 3s 14ms/step - loss: 5.2136 - accuracy: 0.0832\nEpoch 15/200\n244/244 [==============================] - 3s 14ms/step - loss: 5.0664 - accuracy: 0.0874\nEpoch 16/200\n244/244 [==============================] - 3s 14ms/step - loss: 4.9240 - accuracy: 0.0946\nEpoch 17/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.7841 - accuracy: 0.1048\nEpoch 18/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.6493 - accuracy: 0.1182\nEpoch 19/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.5204 - accuracy: 0.1346\nEpoch 20/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.3931 - accuracy: 0.1484\nEpoch 21/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.2737 - accuracy: 0.1679\nEpoch 22/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.1543 - accuracy: 0.1863\nEpoch 23/200\n244/244 [==============================] - 3s 13ms/step - loss: 4.0439 - accuracy: 0.1997\nEpoch 24/200\n244/244 [==============================] - 3s 14ms/step - loss: 3.9344 - accuracy: 0.2227\nEpoch 25/200\n244/244 [==============================] - 3s 13ms/step - loss: 3.8285 - accuracy: 0.2388\nEpoch 26/200\n244/244 [==============================] - 3s 13ms/step - loss: 3.7256 - accuracy: 0.2554\nEpoch 27/200\n244/244 [==============================] - 3s 13ms/step - loss: 3.6263 - accuracy: 0.2713\nEpoch 28/200\n244/244 [==============================] - 3s 13ms/step - loss: 3.5321 - accuracy: 0.2825\nEpoch 29/200\n244/244 [==============================] - 3s 12ms/step - loss: 3.4418 - accuracy: 0.3045\nEpoch 30/200\n244/244 [==============================] - 3s 12ms/step - loss: 3.3518 - accuracy: 0.3238\nEpoch 31/200\n244/244 [==============================] - 3s 13ms/step - loss: 3.2688 - accuracy: 0.3342\nEpoch 32/200\n244/244 [==============================] - 3s 14ms/step - loss: 3.1872 - accuracy: 0.3483\nEpoch 33/200\n244/244 [==============================] - 3s 14ms/step - loss: 3.1093 - accuracy: 0.3650\nEpoch 34/200\n244/244 [==============================] - 3s 14ms/step - loss: 3.0309 - accuracy: 0.3777\nEpoch 35/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.9569 - accuracy: 0.3902\nEpoch 36/200\n244/244 [==============================] - 3s 12ms/step - loss: 2.8865 - accuracy: 0.4036\nEpoch 37/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.8178 - accuracy: 0.4180\nEpoch 38/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.7513 - accuracy: 0.4353\nEpoch 39/200\n244/244 [==============================] - 3s 12ms/step - loss: 2.6835 - accuracy: 0.4471\nEpoch 40/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.6216 - accuracy: 0.4607\nEpoch 41/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.5630 - accuracy: 0.4724\nEpoch 42/200\n244/244 [==============================] - 3s 12ms/step - loss: 2.5037 - accuracy: 0.4867\nEpoch 43/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.4465 - accuracy: 0.4971\nEpoch 44/200\n244/244 [==============================] - 3s 14ms/step - loss: 2.3911 - accuracy: 0.5081\nEpoch 45/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.3336 - accuracy: 0.5184\nEpoch 46/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.2811 - accuracy: 0.5336\nEpoch 47/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.2278 - accuracy: 0.5444\nEpoch 48/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.1771 - accuracy: 0.5579\nEpoch 49/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.1282 - accuracy: 0.5666\nEpoch 50/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.0806 - accuracy: 0.5759\nEpoch 51/200\n244/244 [==============================] - 3s 13ms/step - loss: 2.0322 - accuracy: 0.5893\nEpoch 52/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.9849 - accuracy: 0.5987\nEpoch 53/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.9383 - accuracy: 0.6073\nEpoch 54/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.8957 - accuracy: 0.6181\nEpoch 55/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.8505 - accuracy: 0.6263\nEpoch 56/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.8084 - accuracy: 0.6371\nEpoch 57/200\n244/244 [==============================] - 3s 12ms/step - loss: 1.7655 - accuracy: 0.6480\nEpoch 58/200\n244/244 [==============================] - 3s 12ms/step - loss: 1.7279 - accuracy: 0.6546\nEpoch 59/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.6855 - accuracy: 0.6621\nEpoch 60/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.6497 - accuracy: 0.6703\nEpoch 61/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.6070 - accuracy: 0.6800\nEpoch 62/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.5709 - accuracy: 0.6877\nEpoch 63/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.5335 - accuracy: 0.6937\nEpoch 64/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.4976 - accuracy: 0.7072\nEpoch 65/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.4620 - accuracy: 0.7096\nEpoch 66/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.4293 - accuracy: 0.7172\nEpoch 67/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.3922 - accuracy: 0.7245\nEpoch 68/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.3618 - accuracy: 0.7307\nEpoch 69/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.3283 - accuracy: 0.7398\nEpoch 70/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.2948 - accuracy: 0.7496\nEpoch 71/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.2651 - accuracy: 0.7527\nEpoch 72/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.2333 - accuracy: 0.7568\nEpoch 73/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.2034 - accuracy: 0.7650\nEpoch 74/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.1774 - accuracy: 0.7710\nEpoch 75/200\n244/244 [==============================] - 4s 15ms/step - loss: 1.1481 - accuracy: 0.7770\nEpoch 76/200\n244/244 [==============================] - 4s 15ms/step - loss: 1.1182 - accuracy: 0.7826\nEpoch 77/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.0907 - accuracy: 0.7864\nEpoch 78/200\n244/244 [==============================] - 3s 14ms/step - loss: 1.0641 - accuracy: 0.7912\nEpoch 79/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.0417 - accuracy: 0.8015\nEpoch 80/200\n244/244 [==============================] - 3s 13ms/step - loss: 1.0161 - accuracy: 0.8008\nEpoch 81/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.9920 - accuracy: 0.8080\nEpoch 82/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.9676 - accuracy: 0.8103\nEpoch 83/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.9406 - accuracy: 0.8215\nEpoch 84/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.9202 - accuracy: 0.8215\nEpoch 85/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.8995 - accuracy: 0.8265\nEpoch 86/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.8757 - accuracy: 0.8320\nEpoch 87/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.8541 - accuracy: 0.8365\nEpoch 88/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.8325 - accuracy: 0.8412\nEpoch 89/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.8124 - accuracy: 0.8448\nEpoch 90/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.7953 - accuracy: 0.8488\nEpoch 91/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.7762 - accuracy: 0.8516\nEpoch 92/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.7604 - accuracy: 0.8533\nEpoch 93/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.7408 - accuracy: 0.8576\nEpoch 94/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.7232 - accuracy: 0.8615\nEpoch 95/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.7071 - accuracy: 0.8667\nEpoch 96/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.6891 - accuracy: 0.8671\nEpoch 97/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.6726 - accuracy: 0.8695\nEpoch 98/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.6592 - accuracy: 0.8756\nEpoch 99/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.6439 - accuracy: 0.8767\nEpoch 100/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.6283 - accuracy: 0.8770\nEpoch 101/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.6166 - accuracy: 0.8825\nEpoch 102/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.6044 - accuracy: 0.8824\nEpoch 103/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.5931 - accuracy: 0.8865\nEpoch 104/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.5755 - accuracy: 0.8868\nEpoch 105/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.5645 - accuracy: 0.8880\nEpoch 106/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.5521 - accuracy: 0.8886\nEpoch 107/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.5392 - accuracy: 0.8912\nEpoch 108/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.5289 - accuracy: 0.8929\nEpoch 109/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.5184 - accuracy: 0.8950\nEpoch 110/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.5073 - accuracy: 0.8956\nEpoch 111/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.5004 - accuracy: 0.8976\nEpoch 112/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4912 - accuracy: 0.8975\nEpoch 113/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4783 - accuracy: 0.8988\nEpoch 114/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4693 - accuracy: 0.8993\nEpoch 115/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.4623 - accuracy: 0.9029\nEpoch 116/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4532 - accuracy: 0.9032\nEpoch 117/200\n244/244 [==============================] - 4s 15ms/step - loss: 0.4436 - accuracy: 0.9055\nEpoch 118/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4376 - accuracy: 0.9061\nEpoch 119/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4300 - accuracy: 0.9053\nEpoch 120/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4208 - accuracy: 0.9085\nEpoch 121/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4142 - accuracy: 0.9075\nEpoch 122/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4082 - accuracy: 0.9076\nEpoch 123/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.4011 - accuracy: 0.9094\nEpoch 124/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3932 - accuracy: 0.9091\nEpoch 125/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.3887 - accuracy: 0.9109\nEpoch 126/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3853 - accuracy: 0.9085\nEpoch 127/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.3800 - accuracy: 0.9093\nEpoch 128/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3738 - accuracy: 0.9113\nEpoch 129/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3706 - accuracy: 0.9122\nEpoch 130/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3620 - accuracy: 0.9108\nEpoch 131/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3580 - accuracy: 0.9132\nEpoch 132/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3536 - accuracy: 0.9125\nEpoch 133/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3537 - accuracy: 0.9111\nEpoch 134/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3462 - accuracy: 0.9140\nEpoch 135/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3395 - accuracy: 0.9145\nEpoch 136/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3376 - accuracy: 0.9127\nEpoch 137/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3335 - accuracy: 0.9153\nEpoch 138/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3306 - accuracy: 0.9143\nEpoch 139/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3266 - accuracy: 0.9152\nEpoch 140/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3262 - accuracy: 0.9140\nEpoch 141/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3216 - accuracy: 0.9152\nEpoch 142/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3182 - accuracy: 0.9150\nEpoch 143/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3233 - accuracy: 0.9143\nEpoch 144/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3324 - accuracy: 0.9120\nEpoch 145/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3182 - accuracy: 0.9153\nEpoch 146/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3092 - accuracy: 0.9153\nEpoch 147/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3073 - accuracy: 0.9157\nEpoch 148/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3041 - accuracy: 0.9158\nEpoch 149/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.3021 - accuracy: 0.9170\nEpoch 150/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2991 - accuracy: 0.9159\nEpoch 151/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.2990 - accuracy: 0.9161\nEpoch 152/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.2963 - accuracy: 0.9170\nEpoch 153/200\n244/244 [==============================] - 4s 14ms/step - loss: 0.2972 - accuracy: 0.9159\nEpoch 154/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2947 - accuracy: 0.9159\nEpoch 155/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.2920 - accuracy: 0.9152\nEpoch 156/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.2929 - accuracy: 0.9159\nEpoch 157/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.2910 - accuracy: 0.9166\nEpoch 158/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2889 - accuracy: 0.9146\nEpoch 159/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2872 - accuracy: 0.9159\nEpoch 160/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2875 - accuracy: 0.9163\nEpoch 161/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2888 - accuracy: 0.9157\nEpoch 162/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3118 - accuracy: 0.9144\nEpoch 163/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.3077 - accuracy: 0.9135\nEpoch 164/200\n244/244 [==============================] - 3s 12ms/step - loss: 0.2900 - accuracy: 0.9161\nEpoch 165/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2816 - accuracy: 0.9157\nEpoch 166/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2788 - accuracy: 0.9158\nEpoch 167/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2782 - accuracy: 0.9162\nEpoch 168/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2777 - accuracy: 0.9157\nEpoch 169/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2871 - accuracy: 0.9152\nEpoch 170/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2796 - accuracy: 0.9154\nEpoch 171/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2789 - accuracy: 0.9155\nEpoch 172/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2756 - accuracy: 0.9163\nEpoch 173/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2746 - accuracy: 0.9161\nEpoch 174/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2761 - accuracy: 0.9146\nEpoch 175/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2752 - accuracy: 0.9152\nEpoch 176/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2728 - accuracy: 0.9163\nEpoch 177/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2727 - accuracy: 0.9153\nEpoch 178/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2714 - accuracy: 0.9155\nEpoch 179/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2718 - accuracy: 0.9139\nEpoch 180/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2705 - accuracy: 0.9163\nEpoch 181/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2707 - accuracy: 0.9166\nEpoch 182/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2691 - accuracy: 0.9175\nEpoch 183/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2701 - accuracy: 0.9166\nEpoch 184/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2707 - accuracy: 0.9157\nEpoch 185/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2714 - accuracy: 0.9161\nEpoch 186/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2815 - accuracy: 0.9148\nEpoch 187/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2736 - accuracy: 0.9150\nEpoch 188/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2691 - accuracy: 0.9164\nEpoch 189/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2676 - accuracy: 0.9152\nEpoch 190/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2659 - accuracy: 0.9159\nEpoch 191/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2657 - accuracy: 0.9161\nEpoch 192/200\n244/244 [==============================] - 4s 14ms/step - loss: 0.2656 - accuracy: 0.9162\nEpoch 193/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2654 - accuracy: 0.9167\nEpoch 194/200\n244/244 [==============================] - 3s 13ms/step - loss: 0.2647 - accuracy: 0.9166\nEpoch 195/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2630 - accuracy: 0.9157\nEpoch 196/200\n244/244 [==============================] - 4s 14ms/step - loss: 0.2652 - accuracy: 0.9146\nEpoch 197/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2648 - accuracy: 0.9154\nEpoch 198/200\n244/244 [==============================] - 4s 15ms/step - loss: 0.2640 - accuracy: 0.9154\nEpoch 199/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2631 - accuracy: 0.9172\nEpoch 200/200\n244/244 [==============================] - 3s 14ms/step - loss: 0.2631 - accuracy: 0.9153\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1d4dec13248>"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "##모델 생성\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, 10, input_length=maxLen-1))\n",
    "#입력데이터의 길이는 maxLen에서 y를 뺀 maxLen-1이 된다. \n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocabSize, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' want to be rich and im not sorry allies wait'"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "def sentence_generation(model, t, cw, n):\n",
    "    initWord = cw # 시작단어 \n",
    "    sentence = ''\n",
    "    for _ in range(n): # 10번 반복한다  _ :10번 반복 하는 동안 값을 받는 변수가 없다. \n",
    "        encoded=t.texts_to_sequences([cw])[0] # [2]\n",
    "        encoded=pad_sequences([encoded], maxlen=23, padding='pre')\n",
    "        # print(encoded) #[2] ->-[0 0 0 0 2]\n",
    "        result = model.predict_classes(encoded)\n",
    "        # print(result) #[3] ==word_index[3]의 index\n",
    "        for word, index in t.word_index.items():\n",
    "            if index==result:\n",
    "                break\n",
    "        cw=cw+\" \"+word \n",
    "        sentence = sentence+\" \"+word\n",
    "    initWord+sentence\n",
    "    return sentence\n",
    "\n",
    "sentence_generation(model, t, 'i', 10) \n",
    "# t: Tokenizer\n",
    "#'i' :시작단어\n",
    "# 단어 10개를 예측 해라"
   ]
  }
 ]
}