{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt(\"diabetes.csv\", delimiter=\",\", dtype=np.float32)\n",
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(759, 8)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "xdata.shape # 759,8\n",
    "ydata.shape # 759,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Python37\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() # 텐서플로우 버전 1로 낮추기 (버전 2 기능 사용불가하게 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 나누고 배열화\n",
    "x_data = np.array(xdata)\n",
    "y_data = np.array(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,8])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([8,1])) # 행렬곱(matmul)해야해서 2,1 로 설정\n",
    "b = tf.Variable(tf.random_normal([1])) # 더해주기만 하면 돼서 1로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 식 정의\n",
    "hf = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hf) + (1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "# 텐서플로우의 타입변경함수\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32) # boolean -> float (True:1, False:0)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype=tf.float32)) # boolean -> float 맞추면 1 틀리면 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 0.8824988\n200 0.82266587\n400 0.7879031\n600 0.7596269\n800 0.73450506\n1000 0.71180207\n1200 0.6912425\n1400 0.67263603\n1600 0.6558114\n1800 0.6406073\n2000 0.6268716\n2200 0.6144621\n2400 0.6032471\n2600 0.59310603\n2800 0.58392835\n3000 0.57561433\n3200 0.5680738\n3400 0.561226\n3600 0.5549986\n3800 0.54932684\n4000 0.5441534\n4200 0.5394269\n4400 0.5351021\n4600 0.5311386\n4800 0.5275003\n5000 0.5241554\n5200 0.5210753\n5400 0.51823485\n5600 0.51561147\n5800 0.513185\n6000 0.51093745\n6200 0.50885266\n6400 0.50691634\n6600 0.50511545\n6800 0.5034384\n7000 0.5018747\n7200 0.5004147\n7400 0.49905023\n7600 0.49777335\n7800 0.49657723\n8000 0.49545556\n8200 0.4944024\n8400 0.49341288\n8600 0.49248177\n8800 0.49160516\n9000 0.49077886\n9200 0.4899994\n9400 0.48926342\n9600 0.4885679\n9800 0.4879101\n10000 0.48728737\n10200 0.48669732\n10400 0.48613796\n10600 0.48560718\n10800 0.4851032\n11000 0.48462436\n11200 0.48416898\n11400 0.48373562\n11600 0.4833231\n11800 0.48292997\n12000 0.4825551\n12200 0.48219746\n12400 0.48185608\n12600 0.48152998\n12800 0.48121825\n13000 0.48092037\n13200 0.48063508\n13400 0.4803621\n13600 0.48010054\n13800 0.47984987\n14000 0.47960955\n14200 0.479379\n14400 0.47915763\n14600 0.47894508\n14800 0.47874087\n15000 0.47854453\n15200 0.47835585\n15400 0.4781742\n15600 0.4779994\n15800 0.477831\n16000 0.47766888\n16200 0.4775126\n16400 0.47736192\n16600 0.4772165\n16800 0.47707626\n17000 0.4769409\n17200 0.4768102\n17400 0.47668388\n17600 0.47656178\n17800 0.47644374\n18000 0.47632965\n18200 0.47621924\n18400 0.47611243\n18600 0.47600892\n18800 0.47590882\n19000 0.4758117\n19200 0.4757177\n19400 0.47562656\n19600 0.4755381\n19800 0.47545233\n20000 0.47536924\n20200 0.47528845\n20400 0.47521\n20600 0.47513393\n20800 0.47506\n21000 0.47498816\n21200 0.47491834\n21400 0.47485042\n21600 0.47478452\n21800 0.47472018\n22000 0.47465774\n22200 0.47459695\n22400 0.47453782\n22600 0.47448015\n22800 0.47442406\n23000 0.47436947\n23200 0.47431615\n23400 0.47426426\n23600 0.47421372\n23800 0.4741644\n24000 0.47411627\n24200 0.4740694\n24400 0.47402367\n24600 0.473979\n24800 0.47393546\n25000 0.47389296\n25200 0.47385138\n25400 0.47381085\n25600 0.4737712\n25800 0.47373262\n26000 0.4736948\n26200 0.47365782\n26400 0.47362173\n26600 0.47358653\n26800 0.47355196\n27000 0.47351822\n27200 0.4734853\n27400 0.47345302\n27600 0.47342145\n27800 0.47339055\n28000 0.47336033\n28200 0.47333077\n28400 0.4733018\n28600 0.4732735\n28800 0.47324574\n29000 0.4732185\n29200 0.47319186\n29400 0.47316584\n29600 0.4731403\n29800 0.47311535\n30000 0.47309077\nhf :  [[0.37649286]\n [0.951345  ]\n [0.18236673]\n [0.9612187 ]\n [0.09542617]\n [0.80354404]\n [0.95471585]\n [0.59711945]\n [0.19886631]\n [0.55889356]\n [0.7285645 ]\n [0.12179697]\n [0.24067077]\n [0.24231178]\n [0.77365524]\n [0.39964762]\n [0.77156365]\n [0.83440447]\n [0.81941986]\n [0.5570183 ]\n [0.7084834 ]\n [0.06439927]\n [0.69390404]\n [0.6832064 ]\n [0.31370628]\n [0.95488364]\n [0.58713645]\n [0.6716306 ]\n [0.727131  ]\n [0.38353452]\n [0.96692085]\n [0.92362773]\n [0.62427634]\n [0.85340995]\n [0.34415817]\n [0.6809191 ]\n [0.8425792 ]\n [0.5175888 ]\n [0.35992908]\n [0.32303387]\n [0.8898696 ]\n [0.10421628]\n [0.38049567]\n [0.0279099 ]\n [0.5534648 ]\n [0.95651203]\n [0.71651167]\n [0.7328802 ]\n [0.959597  ]\n [0.9475697 ]\n [0.95267296]\n [0.18995923]\n [0.29948092]\n [0.9808633 ]\n [0.13895866]\n [0.42468232]\n [0.08708039]\n [0.6917632 ]\n [0.9023458 ]\n [0.4974229 ]\n [0.9728749 ]\n [0.70205253]\n [0.6823968 ]\n [0.88932943]\n [0.6273759 ]\n [0.5741045 ]\n [0.97286546]\n [0.69549465]\n [0.86643505]\n [0.65743417]\n [0.22738689]\n [0.7244091 ]\n [0.94283175]\n [0.9485835 ]\n [0.9206215 ]\n [0.8120444 ]\n [0.35263973]\n [0.89811754]\n [0.9225104 ]\n [0.9418441 ]\n [0.89753854]\n [0.86889833]\n [0.31405562]\n [0.8263984 ]\n [0.54774827]\n [0.8770853 ]\n [0.37030786]\n [0.92613053]\n [0.9675674 ]\n [0.7855185 ]\n [0.81010926]\n [0.71066386]\n [0.73760706]\n [0.55336297]\n [0.9270744 ]\n [0.9863765 ]\n [0.9097489 ]\n [0.537635  ]\n [0.17566991]\n [0.64964277]\n [0.69833463]\n [0.9736728 ]\n [0.78234136]\n [0.7690223 ]\n [0.9368187 ]\n [0.6731106 ]\n [0.934512  ]\n [0.8352679 ]\n [0.42262894]\n [0.3039809 ]\n [0.94893426]\n [0.90165335]\n [0.36455733]\n [0.44696507]\n [0.6434419 ]\n [0.86147094]\n [0.8964261 ]\n [0.94978034]\n [0.07022104]\n [0.74007285]\n [0.8659241 ]\n [0.6790227 ]\n [0.6488746 ]\n [0.745973  ]\n [0.66047823]\n [0.8409444 ]\n [0.8310536 ]\n [0.6806568 ]\n [0.4525672 ]\n [0.37533486]\n [0.3502568 ]\n [0.80669093]\n [0.9550681 ]\n [0.83414334]\n [0.8159307 ]\n [0.87398756]\n [0.44988883]\n [0.81496704]\n [0.8002279 ]\n [0.74527645]\n [0.8873502 ]\n [0.6620255 ]\n [0.5218955 ]\n [0.7380334 ]\n [0.9446136 ]\n [0.7503077 ]\n [0.4462118 ]\n [0.9553648 ]\n [0.5970323 ]\n [0.8312422 ]\n [0.20677257]\n [0.32022482]\n [0.06200126]\n [0.16800064]\n [0.93477416]\n [0.8935786 ]\n [0.95871294]\n [0.06709996]\n [0.52768224]\n [0.7884073 ]\n [0.57805276]\n [0.9005475 ]\n [0.41667652]\n [0.8308763 ]\n [0.5932015 ]\n [0.6608972 ]\n [0.74886507]\n [0.8915249 ]\n [0.8144114 ]\n [0.5861292 ]\n [0.9142512 ]\n [0.8768592 ]\n [0.9659518 ]\n [0.15833786]\n [0.86451346]\n [0.14204893]\n [0.32620764]\n [0.3554576 ]\n [0.92792434]\n [0.6400274 ]\n [0.94499546]\n [0.94084615]\n [0.6167975 ]\n [0.0879055 ]\n [0.15401337]\n [0.594043  ]\n [0.7630403 ]\n [0.6212683 ]\n [0.88135445]\n [0.6087599 ]\n [0.32129675]\n [0.1349402 ]\n [0.9361813 ]\n [0.311368  ]\n [0.90690035]\n [0.91984355]\n [0.7058662 ]\n [0.6252471 ]\n [0.6529841 ]\n [0.53566027]\n [0.7468895 ]\n [0.9654344 ]\n [0.7822183 ]\n [0.8570923 ]\n [0.08225071]\n [0.2868063 ]\n [0.92397195]\n [0.15594119]\n [0.9567733 ]\n [0.21509388]\n [0.22062963]\n [0.3790263 ]\n [0.7229697 ]\n [0.14453739]\n [0.74698436]\n [0.72541416]\n [0.8472023 ]\n [0.67549807]\n [0.10091192]\n [0.33414719]\n [0.7521201 ]\n [0.5073671 ]\n [0.94376516]\n [0.9508612 ]\n [0.72110164]\n [0.28400522]\n [0.01826206]\n [0.6072911 ]\n [0.28710237]\n [0.39454964]\n [0.9674284 ]\n [0.63572055]\n [0.96476644]\n [0.14962605]\n [0.083249  ]\n [0.23578176]\n [0.8264233 ]\n [0.9423591 ]\n [0.8991085 ]\n [0.65817493]\n [0.6581467 ]\n [0.5398598 ]\n [0.10891035]\n [0.5685072 ]\n [0.07899773]\n [0.56832045]\n [0.89897096]\n [0.6953327 ]\n [0.7407432 ]\n [0.9677602 ]\n [0.8406579 ]\n [0.80397666]\n [0.78589636]\n [0.79195565]\n [0.8882171 ]\n [0.31731606]\n [0.329252  ]\n [0.49609888]\n [0.84682494]\n [0.6734494 ]\n [0.70113945]\n [0.82641375]\n [0.26446497]\n [0.43034822]\n [0.644507  ]\n [0.6313689 ]\n [0.37534338]\n [0.92905605]\n [0.8188034 ]\n [0.9507636 ]\n [0.5807028 ]\n [0.7637827 ]\n [0.8521129 ]\n [0.8441162 ]\n [0.7309358 ]\n [0.88591456]\n [0.29679203]\n [0.5589395 ]\n [0.68782526]\n [0.3456649 ]\n [0.8619034 ]\n [0.24162409]\n [0.55825895]\n [0.95664686]\n [0.7902874 ]\n [0.87910396]\n [0.6698915 ]\n [0.4109393 ]\n [0.59078   ]\n [0.41004512]\n [0.38297158]\n [0.6495187 ]\n [0.62986875]\n [0.65617996]\n [0.67904234]\n [0.15449008]\n [0.6524796 ]\n [0.9281422 ]\n [0.4393422 ]\n [0.67050457]\n [0.7517134 ]\n [0.44545576]\n [0.74604595]\n [0.46297434]\n [0.6981586 ]\n [0.9346479 ]\n [0.63652784]\n [0.6864339 ]\n [0.8685727 ]\n [0.5512116 ]\n [0.8643582 ]\n [0.96425986]\n [0.25114238]\n [0.7832202 ]\n [0.22624257]\n [0.7857368 ]\n [0.8397633 ]\n [0.73091877]\n [0.3265695 ]\n [0.816954  ]\n [0.7420243 ]\n [0.73604333]\n [0.13288867]\n [0.8114311 ]\n [0.872944  ]\n [0.6036719 ]\n [0.9548253 ]\n [0.17437357]\n [0.76667476]\n [0.96462077]\n [0.13557315]\n [0.45878083]\n [0.7220273 ]\n [0.26645187]\n [0.12447581]\n [0.85962474]\n [0.9392868 ]\n [0.88454664]\n [0.6354917 ]\n [0.7001037 ]\n [0.55353165]\n [0.7516924 ]\n [0.8543824 ]\n [0.9543963 ]\n [0.7552397 ]\n [0.7840543 ]\n [0.5974431 ]\n [0.9610121 ]\n [0.9558704 ]\n [0.7532847 ]\n [0.24777624]\n [0.66363513]\n [0.30301613]\n [0.78133476]\n [0.1294649 ]\n [0.1818833 ]\n [0.41529286]\n [0.7401421 ]\n [0.34364727]\n [0.53226507]\n [0.85275483]\n [0.68062675]\n [0.90137804]\n [0.96553725]\n [0.77523893]\n [0.05252436]\n [0.42261174]\n [0.861146  ]\n [0.8686199 ]\n [0.6454373 ]\n [0.2401272 ]\n [0.9107658 ]\n [0.9066992 ]\n [0.21446425]\n [0.5974768 ]\n [0.8553887 ]\n [0.892434  ]\n [0.89267147]\n [0.9234488 ]\n [0.89615774]\n [0.9368342 ]\n [0.7009015 ]\n [0.62540287]\n [0.55097383]\n [0.8503983 ]\n [0.89983916]\n [0.15783888]\n [0.847134  ]\n [0.9032886 ]\n [0.28259987]\n [0.6010407 ]\n [0.8930213 ]\n [0.5339502 ]\n [0.94803774]\n [0.19854435]\n [0.86789244]\n [0.6030212 ]\n [0.9161049 ]\n [0.3130784 ]\n [0.6490494 ]\n [0.7628828 ]\n [0.84254706]\n [0.06769741]\n [0.15467691]\n [0.70680726]\n [0.8288362 ]\n [0.38124233]\n [0.8049357 ]\n [0.44911253]\n [0.30279523]\n [0.87732166]\n [0.415574  ]\n [0.9544015 ]\n [0.8333833 ]\n [0.63121724]\n [0.9419557 ]\n [0.6508561 ]\n [0.8296758 ]\n [0.25469962]\n [0.20654276]\n [0.78184193]\n [0.3492295 ]\n [0.41233927]\n [0.9194124 ]\n [0.9315944 ]\n [0.93264294]\n [0.9643153 ]\n [0.7226156 ]\n [0.9237012 ]\n [0.2997481 ]\n [0.33064622]\n [0.46651092]\n [0.96837175]\n [0.610279  ]\n [0.12852842]\n [0.94428897]\n [0.82064164]\n [0.5961875 ]\n [0.827731  ]\n [0.00597051]\n [0.93986046]\n [0.7847631 ]\n [0.7567712 ]\n [0.7726838 ]\n [0.97849274]\n [0.6450617 ]\n [0.78036237]\n [0.7974324 ]\n [0.8571358 ]\n [0.14065292]\n [0.65251446]\n [0.92907214]\n [0.634258  ]\n [0.78405464]\n [0.96848065]\n [0.86903524]\n [0.92078865]\n [0.5671041 ]\n [0.81462026]\n [0.9581058 ]\n [0.7469404 ]\n [0.6680182 ]\n [0.21862262]\n [0.41442332]\n [0.5113695 ]\n [0.59659284]\n [0.552497  ]\n [0.81095755]\n [0.6114235 ]\n [0.79810905]\n [0.85895383]\n [0.76316357]\n [0.69467497]\n [0.4392568 ]\n [0.59444153]\n [0.95280945]\n [0.8608639 ]\n [0.18497449]\n [0.36657596]\n [0.46280426]\n [0.05992308]\n [0.9208015 ]\n [0.12051052]\n [0.91277194]\n [0.9112011 ]\n [0.8653135 ]\n [0.68493503]\n [0.9174851 ]\n [0.3502537 ]\n [0.8191663 ]\n [0.9554591 ]\n [0.2567034 ]\n [0.3974496 ]\n [0.90463996]\n [0.8990613 ]\n [0.6637256 ]\n [0.8286834 ]\n [0.8433478 ]\n [0.85386336]\n [0.20025322]\n [0.7746984 ]\n [0.91927826]\n [0.6830074 ]\n [0.8426264 ]\n [0.73729974]\n [0.87130845]\n [0.9001795 ]\n [0.94864094]\n [0.5560685 ]\n [0.39108148]\n [0.8215768 ]\n [0.8148598 ]\n [0.9807947 ]\n [0.7722192 ]\n [0.7119186 ]\n [0.39137685]\n [0.72978586]\n [0.9540287 ]\n [0.97027147]\n [0.91393566]\n [0.70288175]\n [0.7039314 ]\n [0.81139517]\n [0.42931592]\n [0.81542885]\n [0.8377842 ]\n [0.9085078 ]\n [0.60640156]\n [0.7613877 ]\n [0.942731  ]\n [0.4491679 ]\n [0.5026732 ]\n [0.65785724]\n [0.7261391 ]\n [0.7014774 ]\n [0.91913676]\n [0.94169635]\n [0.14950442]\n [0.07829106]\n [0.75896144]\n [0.4810081 ]\n [0.1995689 ]\n [0.87818277]\n [0.9231707 ]\n [0.7598664 ]\n [0.95079446]\n [0.9295592 ]\n [0.7916479 ]\n [0.8612593 ]\n [0.7509717 ]\n [0.53803474]\n [0.8152709 ]\n [0.63054335]\n [0.06458655]\n [0.9153764 ]\n [0.90274835]\n [0.75618994]\n [0.9345716 ]\n [0.8765813 ]\n [0.90759563]\n [0.5532279 ]\n [0.687307  ]\n [0.91934717]\n [0.7908883 ]\n [0.86820173]\n [0.92118573]\n [0.58092695]\n [0.7950741 ]\n [0.85083294]\n [0.52980447]\n [0.54269326]\n [0.06468281]\n [0.21223167]\n [0.8684132 ]\n [0.6895626 ]\n [0.6986761 ]\n [0.5928407 ]\n [0.9586248 ]\n [0.41292652]\n [0.85734695]\n [0.21116376]\n [0.93632853]\n [0.2912146 ]\n [0.77624315]\n [0.58041054]\n [0.87787646]\n [0.5722707 ]\n [0.16663042]\n [0.8198555 ]\n [0.9521545 ]\n [0.32319546]\n [0.9366585 ]\n [0.9037804 ]\n [0.8935692 ]\n [0.8435027 ]\n [0.3682245 ]\n [0.27157778]\n [0.70115817]\n [0.11369503]\n [0.9675131 ]\n [0.2723875 ]\n [0.9442879 ]\n [0.8951446 ]\n [0.342228  ]\n [0.14976537]\n [0.71925414]\n [0.39130437]\n [0.875226  ]\n [0.7528341 ]\n [0.9886514 ]\n [0.5773754 ]\n [0.64304364]\n [0.790288  ]\n [0.8429525 ]\n [0.04303002]\n [0.74662983]\n [0.844815  ]\n [0.8614073 ]\n [0.68185616]\n [0.4691692 ]\n [0.6163969 ]\n [0.93827564]\n [0.6633456 ]\n [0.7906611 ]\n [0.8506465 ]\n [0.8798131 ]\n [0.84971786]\n [0.5990166 ]\n [0.8387724 ]\n [0.9169216 ]\n [0.6880131 ]\n [0.97292584]\n [0.82151616]\n [0.6177412 ]\n [0.4977089 ]\n [0.86946225]\n [0.87336594]\n [0.42533386]\n [0.6488963 ]\n [0.15231094]\n [0.56724256]\n [0.8465421 ]\n [0.9631388 ]\n [0.83807606]\n [0.72509634]\n [0.7837969 ]\n [0.9008256 ]\n [0.44026288]\n [0.9510858 ]\n [0.54326105]\n [0.86504436]\n [0.30122775]\n [0.04372111]\n [0.23101938]\n [0.2878667 ]\n [0.71809244]\n [0.8408437 ]\n [0.605845  ]\n [0.7841486 ]\n [0.8301865 ]\n [0.4678084 ]\n [0.31360376]\n [0.9318858 ]\n [0.9218224 ]\n [0.29904366]\n [0.72155166]\n [0.13429138]\n [0.40249586]\n [0.7680796 ]\n [0.7075881 ]\n [0.92524207]\n [0.98715806]\n [0.12141928]\n [0.6991954 ]\n [0.62009025]\n [0.4468408 ]\n [0.71803087]\n [0.767848  ]\n [0.91704005]\n [0.7357944 ]\n [0.42174426]\n [0.705125  ]\n [0.12183428]\n [0.64274925]\n [0.48992154]\n [0.9407832 ]\n [0.5875483 ]\n [0.5223893 ]\n [0.83681685]\n [0.7192102 ]\n [0.41447762]\n [0.7496684 ]\n [0.6829046 ]\n [0.2811165 ]\n [0.5932039 ]\n [0.9055092 ]\n [0.86753917]\n [0.5951067 ]\n [0.78347063]\n [0.25406927]\n [0.8540219 ]\n [0.5651157 ]\n [0.7665411 ]\n [0.36371893]\n [0.67055064]\n [0.8732847 ]\n [0.11114332]\n [0.22537026]\n [0.8628105 ]\n [0.8232888 ]\n [0.8272555 ]\n [0.93822974]\n [0.7974456 ]\n [0.69112325]\n [0.7271283 ]\n [0.8137255 ]\n [0.70863545]\n [0.79780257]\n [0.46902162]\n [0.4356313 ]\n [0.91229963]\n [0.81076384]\n [0.6771484 ]\n [0.19011739]\n [0.8966238 ]\n [0.8688029 ]\n [0.8583212 ]\n [0.69088316]\n [0.9203086 ]\n [0.8822692 ]\n [0.7953479 ]\n [0.36413833]\n [0.9048588 ]\n [0.9265102 ]\n [0.31536013]\n [0.10565975]\n [0.7577817 ]\n [0.324967  ]\n [0.79206634]\n [0.23906162]\n [0.44936675]\n [0.40202653]\n [0.7641237 ]\n [0.9000995 ]\n [0.0915269 ]\n [0.34629512]\n [0.58150816]\n [0.5026016 ]\n [0.517549  ]\n [0.80948687]\n [0.12192246]\n [0.9330967 ]\n [0.12445046]\n [0.89741313]\n [0.7591453 ]\n [0.7321661 ]\n [0.85134906]\n [0.7413527 ]\n [0.92255014]] pred :  [[0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]] acc :  0.77338606\n"
    }
   ],
   "source": [
    "with tf.Session() as sess : #sess = tf.Session() 말고 이걸 하는이유 : 메모리자원 확보\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(30001):\n",
    "        _, cv = sess.run([train,cost], feed_dict={x:x_data, y:y_data})\n",
    "        if step%200==0:\n",
    "            print(step,cv)\n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "    print(\"hf : \",h,\"pred : \",p,\"acc : \",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연습문제 : 트레이닝 / 테스트 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x_data,y_data,test_size=0.3, random_state=321, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(531, 8)\n(228, 8)\n(531, 1)\n(228, 1)\n"
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 1.1694802\n200 0.8229727\n400 0.7516569\n600 0.72043204\n800 0.6968181\n1000 0.6763029\n1200 0.6580415\n1400 0.6417188\n1600 0.6271112\n1800 0.6140241\n2000 0.60228276\n2200 0.5917314\n2400 0.5822318\n2600 0.573662\n2800 0.5659145\n3000 0.5588957\n3200 0.5525231\n3400 0.54672456\n3600 0.54143727\n3800 0.536606\n4000 0.53218263\n4200 0.5281245\n4400 0.5243945\n4600 0.5209597\n4800 0.5177911\n5000 0.51486313\n5200 0.5121532\n5400 0.50964093\n5600 0.50730854\n5800 0.5051398\n6000 0.50312066\n6200 0.50123817\n6400 0.4994808\n6600 0.49783814\n6800 0.49630094\n7000 0.49486086\n7200 0.49351004\n7400 0.49224174\n7600 0.49104986\n7800 0.48992828\n8000 0.48887205\n8200 0.48787653\n8400 0.48693722\n8600 0.48605013\n8800 0.48521185\n9000 0.48441884\n9200 0.48366827\n9400 0.48295707\n9600 0.4822828\n9800 0.4816431\n10000 0.48103565\n10200 0.48045838\n10400 0.4799097\n10600 0.4793875\n10800 0.47889048\n11000 0.47841692\n11200 0.4779654\n11400 0.4775349\n11600 0.4771239\n11800 0.47673148\n12000 0.47635654\n12200 0.475998\n12400 0.47565508\n12600 0.47532693\n12800 0.47501263\n13000 0.47471154\n13200 0.47442293\n13400 0.4741462\n13600 0.47388062\n13800 0.47362572\n14000 0.47338092\n14200 0.4731457\n14400 0.47291955\n14600 0.47270206\n14800 0.47249284\n15000 0.47229156\n15200 0.4720977\n15400 0.47191086\n15600 0.47173086\n15800 0.47155732\n16000 0.47139\n16200 0.47122845\n16400 0.47107267\n16600 0.4709221\n16800 0.4707767\n17000 0.47063625\n17200 0.4705005\n17400 0.47036925\n17600 0.47024223\n17800 0.47011936\n18000 0.47000042\n18200 0.46988523\n18400 0.46977368\n18600 0.46966565\n18800 0.4695609\n19000 0.46945938\n19200 0.46936095\n19400 0.46926537\n19600 0.46917272\n19800 0.46908277\n20000 0.46899536\n20200 0.46891057\n20400 0.4688282\n20600 0.46874806\n20800 0.46867028\n21000 0.4685946\n21200 0.46852103\n21400 0.46844947\n21600 0.46837994\n21800 0.46831217\n22000 0.46824622\n22200 0.468182\n22400 0.46811944\n22600 0.46805853\n22800 0.46799916\n23000 0.46794137\n23200 0.46788496\n23400 0.46783003\n23600 0.46777645\n23800 0.46772417\n24000 0.46767318\n24200 0.4676234\n24400 0.4675749\n24600 0.4675275\n24800 0.46748123\n25000 0.46743605\n25200 0.4673919\n25400 0.46734884\n25600 0.46730673\n25800 0.46726555\n26000 0.4672253\n26200 0.46718603\n26400 0.46714765\n26600 0.46711004\n26800 0.46707335\n27000 0.46703738\n27200 0.4670022\n27400 0.46696782\n27600 0.46693414\n27800 0.46690127\n28000 0.466869\n28200 0.46683744\n28400 0.46680656\n28600 0.4667763\n28800 0.46674663\n29000 0.4667176\n29200 0.46668914\n29400 0.46666127\n29600 0.4666341\n29800 0.46660724\n30000 0.46658114\nhf :  [[0.14529988]\n [0.91771644]\n [0.65542114]\n [0.88114005]\n [0.86840546]\n [0.7106542 ]\n [0.8851704 ]\n [0.8222579 ]\n [0.55921745]\n [0.51826   ]\n [0.63603073]\n [0.8652091 ]\n [0.9369252 ]\n [0.06193134]\n [0.95765674]\n [0.87715054]\n [0.39462894]\n [0.3793276 ]\n [0.9026062 ]\n [0.34060413]\n [0.7595209 ]\n [0.8911452 ]\n [0.3185242 ]\n [0.72859275]\n [0.7182604 ]\n [0.8074368 ]\n [0.93196005]\n [0.8843445 ]\n [0.652856  ]\n [0.93541753]\n [0.96464133]\n [0.8309568 ]\n [0.8252889 ]\n [0.08551735]\n [0.58076835]\n [0.71283495]\n [0.7176989 ]\n [0.84189415]\n [0.71257406]\n [0.74170023]\n [0.45832643]\n [0.6850059 ]\n [0.7877594 ]\n [0.8897923 ]\n [0.5994867 ]\n [0.36188817]\n [0.7718841 ]\n [0.7745221 ]\n [0.65828705]\n [0.93856716]\n [0.30851436]\n [0.84826434]\n [0.28340042]\n [0.6218185 ]\n [0.4727598 ]\n [0.82592046]\n [0.6857935 ]\n [0.8165668 ]\n [0.8061783 ]\n [0.9495853 ]\n [0.70945144]\n [0.70710415]\n [0.66122353]\n [0.7621463 ]\n [0.8040657 ]\n [0.47989756]\n [0.82766694]\n [0.91839623]\n [0.4008857 ]\n [0.9627633 ]\n [0.93371713]\n [0.6920182 ]\n [0.65640146]\n [0.4524833 ]\n [0.60423905]\n [0.17584923]\n [0.07574096]\n [0.81139326]\n [0.7606387 ]\n [0.86082053]\n [0.95230675]\n [0.6486652 ]\n [0.74292   ]\n [0.7461326 ]\n [0.25173932]\n [0.775805  ]\n [0.8631457 ]\n [0.7535233 ]\n [0.786288  ]\n [0.9089321 ]\n [0.5697956 ]\n [0.6848615 ]\n [0.84016466]\n [0.2998061 ]\n [0.85195607]\n [0.8872483 ]\n [0.64257526]\n [0.4723476 ]\n [0.4346747 ]\n [0.24430168]\n [0.8687259 ]\n [0.8513843 ]\n [0.5847664 ]\n [0.47880033]\n [0.8565356 ]\n [0.49610892]\n [0.842205  ]\n [0.7341548 ]\n [0.84256077]\n [0.13971594]\n [0.7699994 ]\n [0.18834859]\n [0.789443  ]\n [0.53544635]\n [0.67574704]\n [0.886138  ]\n [0.68473077]\n [0.94132626]\n [0.71695566]\n [0.9203496 ]\n [0.30130416]\n [0.7641643 ]\n [0.19270003]\n [0.85179853]\n [0.90399504]\n [0.8978766 ]\n [0.41810817]\n [0.6630169 ]\n [0.84980243]\n [0.7005895 ]\n [0.5701256 ]\n [0.957356  ]\n [0.5965278 ]\n [0.3321095 ]\n [0.98858774]\n [0.838307  ]\n [0.22212085]\n [0.3779775 ]\n [0.11310619]\n [0.68655753]\n [0.7261487 ]\n [0.27151254]\n [0.49623054]\n [0.9517399 ]\n [0.9007366 ]\n [0.82879823]\n [0.30021268]\n [0.7779368 ]\n [0.7984295 ]\n [0.9163548 ]\n [0.7861302 ]\n [0.95971453]\n [0.9144625 ]\n [0.9456409 ]\n [0.61343884]\n [0.87617254]\n [0.11093101]\n [0.9509279 ]\n [0.9541311 ]\n [0.6265397 ]\n [0.94740134]\n [0.95165247]\n [0.96349686]\n [0.74609375]\n [0.94392633]\n [0.8479589 ]\n [0.14944232]\n [0.30015826]\n [0.86745113]\n [0.87951946]\n [0.7526798 ]\n [0.91885936]\n [0.6855001 ]\n [0.20478079]\n [0.6152006 ]\n [0.81988835]\n [0.6268793 ]\n [0.44489452]\n [0.81780565]\n [0.81670684]\n [0.7027723 ]\n [0.830022  ]\n [0.95301044]\n [0.54194343]\n [0.36974823]\n [0.57189363]\n [0.7804607 ]\n [0.93286985]\n [0.9161936 ]\n [0.14569852]\n [0.8670274 ]\n [0.38641804]\n [0.6348469 ]\n [0.2587579 ]\n [0.95927584]\n [0.7706379 ]\n [0.9757016 ]\n [0.88632536]\n [0.20972052]\n [0.9436147 ]\n [0.49081445]\n [0.9701262 ]\n [0.21894005]\n [0.9489139 ]\n [0.74733186]\n [0.8001956 ]\n [0.96327806]\n [0.8626677 ]\n [0.8522574 ]\n [0.41381353]\n [0.10310921]\n [0.93093807]\n [0.5059419 ]\n [0.91779214]\n [0.9205258 ]\n [0.69605297]\n [0.9753394 ]\n [0.8600906 ]\n [0.7926303 ]\n [0.9689403 ]\n [0.4859321 ]\n [0.96034825]\n [0.05534682]\n [0.3826803 ]\n [0.8871198 ]\n [0.60939604]\n [0.45640337]\n [0.8504622 ]] pred :  [[0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [1.]\n [0.]\n [1.]\n [0.]\n [0.]\n [1.]\n [1.]\n [0.]\n [1.]] acc :  0.74561405\n"
    }
   ],
   "source": [
    "with tf.Session() as sess : #sess = tf.Session() 말고 이걸 하는이유 : 메모리자원 확보\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(30001):\n",
    "        _, cv = sess.run([train,cost], feed_dict={x:xtrain, y:ytrain})\n",
    "        if step%200==0:\n",
    "            print(step,cv)\n",
    "    h, p, a = sess.run([hf, predicted, accuracy], feed_dict={x:xtest, y:ytest})\n",
    "    print(\"hf : \",h,\"pred : \",p,\"acc : \",a)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594790836916",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}